{
  "experiment_id": "quick_demo_20250608_005142_95fbb5fa",
  "config": {
    "experiment_name": "quick_demo",
    "description": "Quick demo of experiment tracking system",
    "model_name": "gpt2",
    "dataset_name": "klusai/ds-tf1-en-3m",
    "num_samples": 5,
    "temperature": 0.8,
    "seed": 42,
    "evaluators": [
      "fluency"
    ],
    "tags": [
      "demo",
      "test"
    ],
    "notes": "Quick demonstration of the experiment tracking system"
  },
  "environment": {
    "timestamp": "2025-06-08T00:51:42.016663",
    "platform": {
      "system": "Darwin",
      "machine": "arm64",
      "python_version": "3.13.4"
    },
    "torch": {
      "version": "2.7.1",
      "cuda_available": false,
      "mps_available": true,
      "optimal_device": "mps"
    },
    "git": {
      "commit_hash": "unknown",
      "branch": "unknown",
      "is_dirty": false
    },
    "working_directory": "/Users/mihai/Coding/transformers/gpt2/experiments"
  },
  "status": "completed",
  "start_time": "2025-06-08T00:51:42.070490",
  "results": {
    "evaluator_name": "Fluency",
    "metrics": {
      "avg_repetition_ratio": 0.41207529039731156,
      "std_repetition_ratio": 0.058461076628848516,
      "median_repetition_ratio": 0.4236111111111111,
      "avg_duplicate_word_ratio": 0.0,
      "std_duplicate_word_ratio": 0.0,
      "median_duplicate_word_ratio": 0.0,
      "avg_unique_words": 85.6,
      "std_unique_words": 4.979959839195493,
      "median_unique_words": 85,
      "avg_total_words": 146.2,
      "std_total_words": 9.57601169589929,
      "median_total_words": 144,
      "avg_ttr": 0.5879247096026885,
      "std_ttr": 0.05846107662884854,
      "median_ttr": 0.5763888888888888,
      "avg_msttr": 0.7329576274839432,
      "std_msttr": 0.03958912934218622,
      "median_msttr": 0.7266666666666667,
      "avg_bigram_diversity": 0.9335766038283382,
      "std_bigram_diversity": 0.025658340286101936,
      "median_bigram_diversity": 0.9240506329113924,
      "avg_trigram_diversity": 0.9883325600033744,
      "std_trigram_diversity": 0.016088177000804723,
      "median_trigram_diversity": 1.0,
      "avg_avg_sentence_length": 13.26871794871795,
      "std_avg_sentence_length": 4.438889386716932,
      "median_avg_sentence_length": 13.7,
      "avg_sentence_count": 12.2,
      "std_sentence_count": 4.658325879540846,
      "median_sentence_count": 10,
      "avg_sentence_length_std": 5.626270893885184,
      "std_sentence_length_std": 2.826887321644656,
      "median_sentence_length_std": 4.423620807961684,
      "avg_coherence_score": 0.7431196581196582,
      "std_coherence_score": 0.14463495124343978,
      "median_coherence_score": 0.7222222222222222,
      "avg_avg_word_length": 4.067607335064507,
      "std_avg_word_length": 0.4283923349524348,
      "median_avg_word_length": 3.949685534591195,
      "avg_long_word_ratio": 0.21816286596393578,
      "std_long_word_ratio": 0.07988055380484668,
      "median_long_word_ratio": 0.1830065359477124,
      "avg_word_length_std": 2.119746119489327,
      "std_word_length_std": 0.5105454515771276,
      "median_word_length_std": 1.9247541044437597,
      "overall_fluency_score": 0.700887568476558,
      "avg_text_length": 145.0,
      "std_text_length": 10.0,
      "min_text_length": 136,
      "max_text_length": 159,
      "num_samples": 5
    },
    "samples": [
      {
        "prompt": "In a beautiful river, a dove met a lion. The dove boasted about their abilities, while the lion list...",
        "generated_text": "In a beautiful river, a dove met a lion. The dove boasted about their abilities, while the lion listened quietly. Perhaps it was because it had been taught its true nature that it was intelligent and disciplined. But the lion forced its way out of the enclosed enclosure and went to his room.\n\nThe lo...",
        "repetition_ratio": 0.4236111111111111,
        "duplicate_word_ratio": 0.0,
        "unique_words": 83,
        "total_words": 144,
        "ttr": 0.5763888888888888,
        "msttr": 0.7072727272727272,
        "bigram_diversity": 0.9230769230769231,
        "trigram_diversity": 1.0,
        "avg_sentence_length": 11.076923076923077,
        "sentence_count": 13,
        "sentence_length_std": 3.616202853397895,
        "coherence_score": 0.8461538461538461,
        "avg_word_length": 3.9166666666666665,
        "long_word_ratio": 0.20833333333333334,
        "word_length_std": 2.198219241151308
      },
      {
        "prompt": "Once upon a time, in a peaceful field, there lived a dove and a rabbit. The dove was known for being...",
        "generated_text": "Once upon a time, in a peaceful field, there lived a dove and a rabbit. The dove was known for being very proud, while the rabbit was humble and kind. The two dove and rabbit, however, both had no skin, and so had no tongue. The rabbit possessed great strength, and so had grown a lot taller, so he h...",
        "repetition_ratio": 0.46540880503144655,
        "duplicate_word_ratio": 0.0,
        "unique_words": 85,
        "total_words": 159,
        "ttr": 0.5345911949685535,
        "msttr": 0.6866666666666666,
        "bigram_diversity": 0.9240506329113924,
        "trigram_diversity": 0.9681528662420382,
        "avg_sentence_length": 17.666666666666668,
        "sentence_count": 9,
        "sentence_length_std": 3.5355339059327378,
        "coherence_score": 0.7222222222222222,
        "avg_word_length": 3.949685534591195,
        "long_word_ratio": 0.18238993710691823,
        "word_length_std": 1.8169342036754195
      },
      {
        "prompt": "A ant and a grasshopper were walking through a forest. They found a problem that needed solving.",
        "generated_text": "A ant and a grasshopper were walking through a forest. They found a problem that needed solving. \"Aetiology is a point of pride. The relative importance of the genes is higher than that for knowledge or scientific analysis,\" he says. \"In the beginning the 'anomalies' could be considered not just a l...",
        "repetition_ratio": 0.31386861313868614,
        "duplicate_word_ratio": 0.0,
        "unique_words": 94,
        "total_words": 137,
        "ttr": 0.6861313868613139,
        "msttr": 0.7855855855855856,
        "bigram_diversity": 0.9632352941176471,
        "trigram_diversity": 1.0,
        "avg_sentence_length": 13.7,
        "sentence_count": 10,
        "sentence_length_std": 6.272515001532037,
        "coherence_score": 0.9,
        "avg_word_length": 4.759124087591241,
        "long_word_ratio": 0.35766423357664234,
        "word_length_std": 2.969267951585471
      },
      {
        "prompt": "Once upon a time, in a peaceful garden, there lived a mouse and a turtle. The mouse was known for be...",
        "generated_text": "Once upon a time, in a peaceful garden, there lived a mouse and a turtle. The mouse was known for being very proud, while the turtle was humble and kind. Why, then, did the mouse, who had more than 100,000 eggs on its back, run so fast?\n\nBecause the turtle did not have the organs necessary to digest...",
        "repetition_ratio": 0.4444444444444444,
        "duplicate_word_ratio": 0.0,
        "unique_words": 85,
        "total_words": 153,
        "ttr": 0.5555555555555556,
        "msttr": 0.7266666666666667,
        "bigram_diversity": 0.9013157894736842,
        "trigram_diversity": 0.9735099337748344,
        "avg_sentence_length": 17.0,
        "sentence_count": 9,
        "sentence_length_std": 10.283481900601567,
        "coherence_score": 0.7222222222222222,
        "avg_word_length": 4.111111111111111,
        "long_word_ratio": 0.1830065359477124,
        "word_length_std": 1.9247541044437597
      },
      {
        "prompt": "A hare and a dove were walking through a farm. They found a problem that needed solving.",
        "generated_text": "A hare and a dove were walking through a farm. They found a problem that needed solving. The goat was in a hurry. He had run down a hard road. It was getting lonely. He was moving on. He took a good look at the farm and a stone wall and saw a little pond. He saw two fish. A forklift was moving. Ther...",
        "repetition_ratio": 0.41304347826086957,
        "duplicate_word_ratio": 0.0,
        "unique_words": 81,
        "total_words": 138,
        "ttr": 0.5869565217391305,
        "msttr": 0.7585964912280702,
        "bigram_diversity": 0.9562043795620438,
        "trigram_diversity": 1.0,
        "avg_sentence_length": 6.9,
        "sentence_count": 20,
        "sentence_length_std": 4.423620807961684,
        "coherence_score": 0.525,
        "avg_word_length": 3.601449275362319,
        "long_word_ratio": 0.15942028985507245,
        "word_length_std": 1.6895550965906763
      }
    ],
    "config": {
      "model_name": "gpt2",
      "dataset_name": "klusai/ds-tf1-en-3m",
      "dataset_split": "test",
      "num_samples": 5,
      "max_length": 512,
      "temperature": 0.8,
      "seed": 42,
      "device": "mps",
      "output_dir": null,
      "save_generations": false,
      "verbose": true
    },
    "execution_time": 48.16282296180725,
    "timestamp": "2025-06-08T00:52:43.418562",
    "metadata": {
      "model_name": "gpt2",
      "temperature": 0.8,
      "analysis_type": "lexical_diversity_and_repetition"
    }
  },
  "end_time": "2025-06-08T00:52:43.419814"
}
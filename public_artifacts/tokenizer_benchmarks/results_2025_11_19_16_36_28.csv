name,vocab_size,num_texts,total_chars,total_tokens,total_words,avg_tokens_per_text,avg_chars_per_text,avg_tokens_per_char,avg_tokens_per_word,compression_ratio,vocab_usage,vocab_usage_ratio,tokenization_time_seconds,texts_per_second,tokens_per_second,std_tokens_per_text,min_tokens_per_text,max_tokens_per_text
Romanian-trained (Unigram),32000,21216,902137,526352,156055,24.80920060331825,42.521540346908,0.5834501855039755,3.372862131940662,1.7139423807642034,4971,0.15534375,1.2950117588043213,16382.862824032301,406445.7302580623,44.68814116292786,0,1855
Romanian-trained (Bpe),32000,21216,902137,328632,156055,15.489819004524886,42.521540346908,0.3642817000078702,2.105872929415911,2.7451282893936075,6777,0.21178125,1.0251941680908203,20694.616356928505,320555.86173690273,30.193623063867253,1,1109
Pre-trained: gpt2,50257,21216,902137,368336,156055,17.361236802413273,42.521540346908,0.40829275376134666,2.360296049469738,2.4492229920507365,7301,0.14527329526235153,1.6115262508392334,13165.15941887472,228563.45021260556,27.200869925696566,1,1176
Pre-trained: bert-base-uncased,30522,21216,902137,364989,156055,17.20347850678733,42.521540346908,0.4045826742501416,2.3388484829066676,2.471682708246002,4691,0.15369241858331695,1.333927869796753,15904.907964200962,273619.7423145619,27.323653508771685,1,1191
Pre-trained: roberta-base,50265,21216,902137,368336,156055,17.361236802413273,42.521540346908,0.40829275376134666,2.360296049469738,2.4492229920507365,7301,0.14525017407738983,1.197873830795288,17711.38116099786,307491.4824338851,27.200869925696566,1,1176
Pre-trained: distilgpt2,50257,21216,902137,368336,156055,17.361236802413273,42.521540346908,0.40829275376134666,2.360296049469738,2.4492229920507365,7301,0.14527329526235153,1.1408641338348389,18596.429996169383,322857.024842998,27.200869925696566,1,1176
